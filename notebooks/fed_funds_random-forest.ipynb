{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df2d9318",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nick/fed_funds_forecast/venv/lib/python3.12/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fed Funds Rate</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.80</td>\n",
       "      <td>1954-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.22</td>\n",
       "      <td>1954-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.07</td>\n",
       "      <td>1954-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.85</td>\n",
       "      <td>1954-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.83</td>\n",
       "      <td>1954-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.28</td>\n",
       "      <td>1954-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.39</td>\n",
       "      <td>1955-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.29</td>\n",
       "      <td>1955-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.35</td>\n",
       "      <td>1955-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.43</td>\n",
       "      <td>1955-04-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fed Funds Rate       Date\n",
       "0            0.80 1954-07-01\n",
       "1            1.22 1954-08-01\n",
       "2            1.07 1954-09-01\n",
       "3            0.85 1954-10-01\n",
       "4            0.83 1954-11-01\n",
       "5            1.28 1954-12-01\n",
       "6            1.39 1955-01-01\n",
       "7            1.29 1955-02-01\n",
       "8            1.35 1955-03-01\n",
       "9            1.43 1955-04-01"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression,Lasso,Ridge\n",
    "from sklearn.ensemble import GradientBoostingRegressor,RandomForestRegressor,BaggingRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import root_mean_squared_error,r2_score\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import fredapi as fr\n",
    "import fredapi.fred as fr\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "FRED_API_KEY = os.getenv(\"FRED_API_KEY\")\n",
    "\n",
    "\n",
    "fred = fr.Fred(FRED_API_KEY)\n",
    "\n",
    "\n",
    "\n",
    "ffr = fred.get_series(\"FEDFUNDS\")\n",
    "ffr.name = \"Fed Funds Rate\"\n",
    "\n",
    "ffr = fred.get_series(\"FEDFUNDS\")\n",
    "ffr.name = \"Fed Funds Rate\"\n",
    "\n",
    "data = pd.DataFrame(ffr).dropna()\n",
    "data = data.reset_index()\n",
    "data['Date'] = data['index']\n",
    "\n",
    "\n",
    "data.drop(\"index\",axis=1,inplace=True)\n",
    "data.head(10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fae24ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Model        R2      RMSE  Cross-val Scores\n",
      "0           LinearRegression  0.068586  2.998522        -11.641676\n",
      "1                      lasso -0.004599  3.114099        -13.050213\n",
      "2                      ridge  0.069840  2.996504        -11.641329\n",
      "3  GradientBoostingRegressor  0.965586  0.576376         -0.446371\n",
      "4           BaggingRegressor  0.990752  0.298785         -0.206648\n",
      "5         xBGboostRegression  0.961390  0.610500         -0.291863\n",
      "6               randomforest  0.991034  0.294194         -0.204016\n"
     ]
    }
   ],
   "source": [
    "X = data.drop(\"Fed Funds Rate\",axis=1)\n",
    "y = data['Fed Funds Rate']\n",
    "\n",
    "X_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.13,random_state=42)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "\n",
    "def evaluate(y_test,pred,model_name,r2,rmse,cv_scores):\n",
    "\n",
    "\n",
    "    result = {\n",
    "        \"Model\": model_name,\n",
    "        \"R2\": r2,\n",
    "        \"RMSE\": rmse,\n",
    "        \"Cross-val Scores\":cv_scores.mean()\n",
    "    }\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "model_dict = []\n",
    "models = {\n",
    "    \"LinearRegression\":LinearRegression(),\n",
    "    \"lasso\":Lasso(),\n",
    "    \"ridge\":Ridge(),\n",
    "    \"GradientBoostingRegressor\":GradientBoostingRegressor(),\n",
    "    \"BaggingRegressor\":BaggingRegressor(),\n",
    "    \"xBGboostRegression\":XGBRegressor(),\n",
    "    \"randomforest\":RandomForestRegressor(),\n",
    "}\n",
    "\n",
    "\n",
    "for model_name,model in models.items():\n",
    "    model.fit(X_train_scaled,y_train)\n",
    "    pred = model.predict(X_test_scaled)\n",
    "    mse = root_mean_squared_error(y_test,pred)\n",
    "    r2 = r2_score(y_test,pred)\n",
    "    cv_scores = cross_val_score(model, X_train_scaled,y_train,cv=10,scoring=\"neg_mean_squared_error\")\n",
    "    model_results = evaluate(y_test, pred, model_name,r2,mse,cv_scores)\n",
    "    model_dict.append(model_results)\n",
    "\n",
    "\n",
    "\n",
    "df_results = pd.DataFrame(model_dict)\n",
    "print(df_results.head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4d7473d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/05 05:37:54 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params for LinearRegression: {'copy_X': True, 'fit_intercept': True, 'n_jobs': 1000, 'positive': False}\n",
      "Best Score for LinearRegression: -3.4008840280728942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/09/05 05:37:56 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025/09/05 05:37:56 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/09/05 05:37:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "/home/nick/fed_funds_forecast/venv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.350e+00, tolerance: 6.804e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/nick/fed_funds_forecast/venv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.777e+01, tolerance: 7.114e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/nick/fed_funds_forecast/venv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.943e+01, tolerance: 7.254e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "2025/09/05 05:37:58 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params for lasso: {'alpha': 0.001}\n",
      "Best Score for lasso: -3.4008836413326518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/09/05 05:38:00 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025/09/05 05:38:00 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/09/05 05:38:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025/09/05 05:38:01 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params for ridge: {'alpha': 0.01}\n",
      "Best Score for ridge: -3.4008831870826928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/09/05 05:38:03 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025/09/05 05:38:03 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/09/05 05:38:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025/09/05 05:38:08 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params for GradientBoostingRegresser: {'learning_rate': 0.1, 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best Score for GradientBoostingRegresser: -0.5917671437158843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/09/05 05:38:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025/09/05 05:38:10 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/09/05 05:38:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025/09/05 05:38:12 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params for baggingREgressor: {'max_features': 1.0, 'max_samples': 0.6, 'n_estimators': 100}\n",
      "Best Score for baggingREgressor: -0.4834453534392096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/09/05 05:38:14 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025/09/05 05:38:14 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/09/05 05:38:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "/home/nick/fed_funds_forecast/venv/lib/python3.12/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/nick/fed_funds_forecast/venv/lib/python3.12/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/nick/fed_funds_forecast/venv/lib/python3.12/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/nick/fed_funds_forecast/venv/lib/python3.12/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/nick/fed_funds_forecast/venv/lib/python3.12/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/nick/fed_funds_forecast/venv/lib/python3.12/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/nick/fed_funds_forecast/venv/lib/python3.12/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/nick/fed_funds_forecast/venv/lib/python3.12/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/nick/fed_funds_forecast/venv/lib/python3.12/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/nick/fed_funds_forecast/venv/lib/python3.12/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/nick/fed_funds_forecast/venv/lib/python3.12/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/nick/fed_funds_forecast/venv/lib/python3.12/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "2025/09/05 05:38:36 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params for xGBRegressor: {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 7, 'min_child_weight': 1, 'n_estimators': 500, 'reg_alpha': 0.1, 'reg_lambda': 0, 'subsample': 0.8}\n",
      "Best Score for xGBRegressor: -0.6209462009593243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/09/05 05:38:38 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025/09/05 05:38:38 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/09/05 05:38:40 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025/09/05 05:38:42 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params for randomforestregressor: {'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 50}\n",
      "Best Score for randomforestregressor: -0.4905534238340443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/09/05 05:38:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025/09/05 05:38:41 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/09/05 05:38:43 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#hyper-parameter tuning\n",
    "\n",
    "mlflow.set_experiment(\"fed-funds-rate-gridsearch\")\n",
    "\n",
    "linearregression_params = {\n",
    "'copy_X': [True,False], \n",
    "'fit_intercept': [True,False], \n",
    "'n_jobs': [1000,5000,10000], \n",
    "'positive': [True,False]}\n",
    "\n",
    "\n",
    "\n",
    "lasso_params = {\n",
    "    'alpha': [1e-15,1e-10,1e-8,1e-3,1e-2,1,5,10,20,30,35,40,45,50,55,100]\n",
    "    }\n",
    "\n",
    "\n",
    "ridge_params = {\n",
    "    'alpha':[1e-15,1e-10,1e-8,1e-3,1e-2,1,5,10,20,30,35,40,45,50,55,100]\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "gradientboosting_params = {\n",
    "    'n_estimators': [50,100,200],\n",
    "    'learning_rate': [0.01,0.1,0.2],\n",
    "    'max_depth': [3,4,5],\n",
    "    'min_samples_split': [2,5,10]\n",
    "    }\n",
    "\n",
    "bagginregression_params = {\n",
    "    'n_estimators': [50,100,200],\n",
    "    'max_samples' : [1.0,0.8,0.6],\n",
    "    'max_features': [1.0,0.8,0.6]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "xgboost_grid = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_child_weight': [1, 3],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0],\n",
    "    'reg_alpha': [0, 0.1],\n",
    "    'reg_lambda': [0, 0.1]\n",
    "}\n",
    "\n",
    "\n",
    "random_forest_params = {\n",
    "    'n_estimators': [50,100,200],\n",
    "    'min_samples_leaf':[1,2,4],\n",
    "    'max_features': ['sqrt','log2',None],\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "models = {\n",
    "    \"LinearRegression\":(LinearRegression(),linearregression_params),\n",
    "    \"lasso\":(Lasso(),lasso_params),\n",
    "    \"ridge\":(Ridge(),ridge_params),\n",
    "    \"GradientBoostingRegresser\":(GradientBoostingRegressor(),gradientboosting_params),\n",
    "    \"baggingREgressor\":(BaggingRegressor(),bagginregression_params),\n",
    "    \"xGBRegressor\":(XGBRegressor(),xgboost_grid),\n",
    "    \"randomforestregressor\":(RandomForestRegressor(),random_forest_params),\n",
    "    }\n",
    "\n",
    "best_scores = []\n",
    "\n",
    "for model_name,(model,params) in models.items():\n",
    "    grid_search = GridSearchCV(model,params,scoring=\"neg_root_mean_squared_error\",cv=4,n_jobs=-1)\n",
    "    grid_search.fit(X_train_scaled,y_train)\n",
    "    print(f'Best Params for {model_name}: {grid_search.best_params_}')\n",
    "    print(f'Best Score for {model_name}: {grid_search.best_score_}')\n",
    "    best_scores.append({\"Model\":model_name,\"neg_root_mean_squared_log_error\":grid_search.best_score_})\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        mlflow.log_params(grid_search.best_params_)\n",
    "        mlflow.log_metric(\"best_score\", grid_search.best_score_)\n",
    "        mlflow.sklearn.log_model(grid_search.best_estimator_, model_name)\n",
    "        best_scores.append({\"Model\": model_name, \"Best Score\": grid_search.best_score_})\n",
    "        mlflow.sklearn.log_model(grid_search.best_estimator_, model_name)\n",
    "        best_scores.append({\"Model\": model_name, \"Best Score\": grid_search.best_score_,\"Best Params\":grid_search.best_params_})\n",
    "\n",
    "\n",
    "best_scores_df = pd.DataFrame(best_scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "648ffbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score From Best Model and HyperParameter Tuning: 99.02%\n",
      "Root Mean Squared Error from Best Model with Optimized HyperParamters: 0.3077749264594874\n"
     ]
    }
   ],
   "source": [
    "Best_Model = RandomForestRegressor(max_features=\"log2\",min_samples_leaf=1,n_estimators=50).fit(X_train_scaled,y_train)\n",
    "\n",
    "pred = Best_Model.predict(X_test_scaled)\n",
    "print(f'R2 Score From Best Model and HyperParameter Tuning: {r2_score(y_test,pred)*100:.2f}%')\n",
    "print(f'Root Mean Squared Error from Best Model with Optimized HyperParamters: {root_mean_squared_error(y_test,pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f0fb611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Vs Actual Prices\n",
      "\n",
      "     Actual  Predicted\n",
      "23     2.71     2.7458\n",
      "30     2.84     2.9378\n",
      "31     3.00     2.9500\n",
      "33     3.00     2.9906\n",
      "39     3.50     3.3796\n",
      "..      ...        ...\n",
      "833    5.33     5.3300\n",
      "835    5.33     5.3300\n",
      "840    5.33     5.3200\n",
      "849    4.33     4.3330\n",
      "850    4.33     4.3300\n",
      "\n",
      "[112 rows x 2 columns]\n",
      "     Actual  Predicted\n",
      "23     2.71     2.7458\n",
      "30     2.84     2.9378\n",
      "31     3.00     2.9500\n",
      "33     3.00     2.9906\n",
      "39     3.50     3.3796\n",
      "49     1.53     1.5008\n",
      "63     3.98     3.7330\n",
      "65     3.99     3.8876\n",
      "66     3.99     3.8870\n",
      "67     3.97     3.8684\n",
      "72     3.23     3.2980\n",
      "76     2.44     2.5478\n",
      "77     1.98     2.4314\n",
      "78     1.45     2.3782\n",
      "86     1.88     2.1912\n",
      "96     2.71     2.7476\n",
      "109    3.49     3.0694\n",
      "110    3.48     3.4352\n",
      "120    3.42     3.4962\n",
      "136    4.10     4.0940\n",
      "     Actual  Predicted\n",
      "706    0.11     0.1390\n",
      "709    0.08     0.0888\n",
      "713    0.09     0.0778\n",
      "733    0.14     0.1350\n",
      "740    0.36     0.3730\n",
      "746    0.40     0.4062\n",
      "753    0.90     0.8562\n",
      "767    1.82     1.8612\n",
      "778    2.39     2.4122\n",
      "788    0.65     1.1480\n",
      "792    0.09     0.0820\n",
      "802    0.06     0.0754\n",
      "808    0.08     0.0824\n",
      "819    3.08     2.8402\n",
      "830    5.33     5.3258\n",
      "833    5.33     5.3300\n",
      "835    5.33     5.3300\n",
      "840    5.33     5.3200\n",
      "849    4.33     4.3330\n",
      "850    4.33     4.3300\n"
     ]
    }
   ],
   "source": [
    "pred_vs_actual = pd.DataFrame({\n",
    "    'Actual': y_test.values,\n",
    "    'Predicted': pred\n",
    "}, index=y_test.index)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pred_vs_actual.sort_index(inplace=True)\n",
    "print('Predicted Vs Actual Prices\\n')\n",
    "print(pred_vs_actual)\n",
    "\n",
    "print(pred_vs_actual.head(20))\n",
    "print(pred_vs_actual.tail(20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
