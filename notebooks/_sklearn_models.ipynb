{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5abd3e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FEDFUNDS</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.80</td>\n",
       "      <td>1954-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.22</td>\n",
       "      <td>1954-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.07</td>\n",
       "      <td>1954-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.85</td>\n",
       "      <td>1954-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.83</td>\n",
       "      <td>1954-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.28</td>\n",
       "      <td>1954-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.39</td>\n",
       "      <td>1955-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.29</td>\n",
       "      <td>1955-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.35</td>\n",
       "      <td>1955-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.43</td>\n",
       "      <td>1955-04-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FEDFUNDS       date\n",
       "0      0.80 1954-07-01\n",
       "1      1.22 1954-08-01\n",
       "2      1.07 1954-09-01\n",
       "3      0.85 1954-10-01\n",
       "4      0.83 1954-11-01\n",
       "5      1.28 1954-12-01\n",
       "6      1.39 1955-01-01\n",
       "7      1.29 1955-02-01\n",
       "8      1.35 1955-03-01\n",
       "9      1.43 1955-04-01"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression,Lasso,Ridge\n",
    "from sklearn.ensemble import GradientBoostingRegressor,RandomForestRegressor,BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import root_mean_squared_error,r2_score,mean_absolute_percentage_error\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from scripts.data_ingestion import DataIngestion\n",
    "from scripts.data_transformation import DataTransformation\n",
    "\n",
    "from helpers.config import load_config\n",
    "from helpers.logger import logger\n",
    "\n",
    "\n",
    "config = load_config()\n",
    "\n",
    "data = DataIngestion(config).fetch_fred_data()\n",
    "\n",
    "\n",
    "data.head(10)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d563fc",
   "metadata": {},
   "source": [
    "### Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b2e7b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-05 14:52:23 - INFO - helpers.logger - 44 - shape of training data: (857, 1)\n",
      "2025-12-05 14:52:23 - INFO - helpers.logger - 53 - Length of training data: 685\n",
      "2025-12-05 14:52:23 - INFO - helpers.logger - 54 - Length of testing data: 172\n",
      "2025-12-05 14:52:23 - INFO - helpers.logger - 73 - Shape of training data scaled: (685, 1)\n",
      "2025-12-05 14:52:23 - INFO - helpers.logger - 74 - Shape of testing data scaled: (172, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((685, 1), (172, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train,test = DataTransformation(config).transform()\n",
    "\n",
    "\n",
    "train.shape,test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc1f4f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score->Model Name: LinearRegression 10.67\n",
      "Mean-Absolute Percentage Error: LinearRegression--4.528\n",
      "Best Score for model: LinearRegression<===>-11.192741097421976\n",
      "Best Params for model: LinearRegression<====>{'copy_X': True, 'fit_intercept': True, 'n_jobs': 1000, 'positive': False}\n",
      "R2 Score->Model Name: Lasso 10.67\n",
      "Mean-Absolute Percentage Error: Lasso--4.533\n",
      "Best Score for model: Lasso<===>-11.192740368106886\n",
      "Best Params for model: Lasso<====>{'alpha': 0.001}\n",
      "R2 Score->Model Name: Ridge 10.67\n",
      "Mean-Absolute Percentage Error: Ridge--4.555\n",
      "Best Score for model: Ridge<===>-11.191853092713757\n",
      "Best Params for model: Ridge<====>{'alpha': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nickkats1/Fed-Funds-Forecast/venv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.516e-01, tolerance: 6.865e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/nickkats1/Fed-Funds-Forecast/venv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.066e+00, tolerance: 6.245e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/nickkats1/Fed-Funds-Forecast/venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:516: FitFailedWarning: \n",
      "108 fits failed out of a total of 324.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "108 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nickkats1/Fed-Funds-Forecast/venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/nickkats1/Fed-Funds-Forecast/venv/lib/python3.12/site-packages/sklearn/base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/home/nickkats1/Fed-Funds-Forecast/venv/lib/python3.12/site-packages/sklearn/base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/nickkats1/Fed-Funds-Forecast/venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of GradientBoostingRegressor must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/nickkats1/Fed-Funds-Forecast/venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1135: UserWarning: One or more of the test scores are non-finite: [        nan         nan         nan -6.76110456 -3.83752362 -1.86106722\n",
      " -6.76110456 -3.83752362 -1.86106722         nan         nan         nan\n",
      " -6.00810109 -3.19949133 -1.35539595 -6.00784767 -3.1993568  -1.35618388\n",
      "         nan         nan         nan -5.4549948  -2.64391355 -0.84583596\n",
      " -5.45555712 -2.64455712 -0.84766202         nan         nan         nan\n",
      " -0.89212179 -0.48348744 -0.32039046 -0.89722524 -0.49492373 -0.32159155\n",
      "         nan         nan         nan -0.47126026 -0.31913049 -0.27797151\n",
      " -0.49894034 -0.32507503 -0.27964982         nan         nan         nan\n",
      " -0.34127946 -0.28470536 -0.27919307 -0.35106479 -0.29444736 -0.27749535\n",
      "         nan         nan         nan -0.44335249 -0.29391602 -0.27555975\n",
      " -0.47133148 -0.32340374 -0.27607858         nan         nan         nan\n",
      " -0.32069788 -0.27749508 -0.27961187 -0.33071446 -0.27891173 -0.27984448\n",
      "         nan         nan         nan -0.28414139 -0.27760319 -0.28098692\n",
      " -0.28570087 -0.27452251 -0.27834969]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score->Model Name: GradientBoostingRegressor 96.47\n",
      "Mean-Absolute Percentage Error: GradientBoostingRegressor--0.08108\n",
      "Best Score for model: GradientBoostingRegressor<===>-0.2745225135044963\n",
      "Best Params for model: GradientBoostingRegressor<====>{'learning_rate': 0.2, 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "R2 Score->Model Name: RandomForestRegressor 97.98\n",
      "Mean-Absolute Percentage Error: RandomForestRegressor--0.05693\n",
      "Best Score for model: RandomForestRegressor<===>-0.2004035046388381\n",
      "Best Params for model: RandomForestRegressor<====>{'max_features': 'log2', 'min_samples_leaf': 1, 'n_estimators': 100}\n",
      "R2 Score->Model Name: BaggingRegressor 98.19\n",
      "Mean-Absolute Percentage Error: BaggingRegressor--0.05452\n",
      "Best Score for model: BaggingRegressor<===>-0.20077764146164837\n",
      "Best Params for model: BaggingRegressor<====>{'max_features': 0.6, 'max_samples': 0.8, 'n_estimators': 50}\n",
      "R2 Score->Model Name: XGBRegressor 98.11\n",
      "Mean-Absolute Percentage Error: XGBRegressor--0.09141\n",
      "Best Score for model: XGBRegressor<===>-0.4854641214701011\n",
      "Best Params for model: XGBRegressor<====>{'colsample_bytree': 0.6, 'learning_rate': 0.1, 'max_depth': 9, 'min_child_weight': 5, 'n_estimators': 100, 'subsample': 0.6}\n",
      "R2 Score->Model Name: DecisionTreeRegressor 96.28\n",
      "Mean-Absolute Percentage Error: DecisionTreeRegressor--0.07232\n",
      "Best Score for model: DecisionTreeRegressor<===>-0.28355945787433695\n",
      "Best Params for model: DecisionTreeRegressor<====>{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "# model trainer\n",
    "\n",
    "class ModelTrainer:\n",
    "    \"\"\"Train models for MLFlow and hyper-parameter tuning.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,config: dict, data_transformation: DataTransformation | None = None,\n",
    "        data_ingestion: DataIngestion | None = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initializing ModelTrainer class.\n",
    "        \n",
    "        Args:\n",
    "            config (dict): Configuration file.\n",
    "            data_transformation (DataTransformation):  A instance of the DataTransformation class.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.config = config or load_config()\n",
    "        self.data_transformation = data_transformation or DataTransformation(self.config)\n",
    "        self.data_ingestion = data_ingestion or DataIngestion(self.config)  \n",
    "        \n",
    "        \n",
    "        \n",
    "    def load_models(self):\n",
    "        \"\"\"\n",
    "        params and models loaded for GridSearchCV.\n",
    "        \n",
    "        Returns:\n",
    "            models: sklearn model's for training.\n",
    "            params: parameters for hyperparameter tuning.\n",
    "        \"\"\"\n",
    "        \n",
    "        params = {\n",
    "            \"LinearRegression_params\": {\n",
    "                \"fit_intercept\":[True],\n",
    "                \"copy_X\": [True,False],\n",
    "                \"n_jobs\": [1000,1500,2000],\n",
    "                \"positive\": [True,False]\n",
    "            },\n",
    "            \"Lasso_params\": {\n",
    "                \"alpha\": [1e-15,1e-10,1e-8,1e-3,1e-2,1,5,10,20,30,35,40,45,50,55,100]\n",
    "            },\n",
    "            \"Ridge_params\": {\n",
    "                \"alpha\": [1e-15,1e-10,1e-8,1e-3,1e-2,1,5,10,20,30,35,40,45,50,55,100]\n",
    "            },\n",
    "            \"GradientBoostingRegressor_params\": {\n",
    "                \"n_estimators\": [50, 100, 200],\n",
    "                \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "                \"max_depth\": [3, 4, 5],\n",
    "                \"min_samples_split\": [1, 5,10]\n",
    "            },\n",
    "            \"RandomForestRegressor_params\": {\n",
    "                \"n_estimators\": [50, 100, 200],\n",
    "                \"min_samples_leaf\": [1,2,4],\n",
    "                \"max_features\": ['sqrt', 'log2', None]\n",
    "            },\n",
    "            \"BaggingRegressor_params\": {\n",
    "                \"n_estimators\": [50,100,200],\n",
    "                \"max_samples\": [1.0,0.8,0.6],\n",
    "                \"max_features\": [1.0,0.8,0.6]\n",
    "            },\n",
    "            \"XGBRegressor_params\": {\n",
    "                \"n_estimators\": [100,200,300],\n",
    "                \"max_depth\": [3,5,9],\n",
    "                \"min_child_weight\": [1,3,5],\n",
    "                \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "                \"subsample\": [0.6, 0.8],\n",
    "                \"colsample_bytree\": [0.6, 0.8]\n",
    "            },\n",
    "            \"DecisionTreeRegressor_params\": {\n",
    "                \"max_depth\": [None,10,15],\n",
    "                \"min_samples_split\": [2,5,10],\n",
    "                \"min_samples_leaf\": [1,2,5]\n",
    "            },\n",
    "        }\n",
    "        \n",
    "        # models with hyper-parameters\n",
    "        \n",
    "        models = {\n",
    "            \"LinearRegression\":(LinearRegression(),params[\"LinearRegression_params\"]),\n",
    "            \"Lasso\":(Lasso(),params[\"Lasso_params\"]),\n",
    "            \"Ridge\": (Ridge(), params[\"Ridge_params\"]),\n",
    "            \"GradientBoostingRegressor\":(GradientBoostingRegressor(),params[\"GradientBoostingRegressor_params\"]),\n",
    "            \"RandomForestRegressor\": (RandomForestRegressor(),params[\"RandomForestRegressor_params\"]),\n",
    "            \"BaggingRegressor\":(BaggingRegressor(),params[\"BaggingRegressor_params\"]),\n",
    "            \"XGBRegressor\": (XGBRegressor(),params[\"XGBRegressor_params\"]),\n",
    "            \"DecisionTreeRegressor\":(DecisionTreeRegressor(),params[\"DecisionTreeRegressor_params\"])\n",
    "        }\n",
    "        return params,models\n",
    "    \n",
    "    def split(self):\n",
    "        \"\"\"Split data for training and testing\"\"\"\n",
    "        # get data through DataIngestion\n",
    "        \n",
    "        data = self.data_ingestion.fetch_fred_data()\n",
    "        \n",
    "        # features and targets\n",
    "        \n",
    "        X = data.drop(\"FEDFUNDS\",axis=1)\n",
    "        y = data[\"FEDFUNDS\"]\n",
    "        \n",
    "        # train/test split\n",
    "        \n",
    "        X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.20,random_state=1)\n",
    "        \n",
    "        \n",
    "        # MinMax Scaler\n",
    "        scaler = MinMaxScaler()\n",
    "        \n",
    "        \n",
    "        # scaled training and testing data\n",
    "        \n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        return X_train_scaled,X_test_scaled,y_train,y_test\n",
    "        \n",
    "    \n",
    "    def train(self):\n",
    "        \"\"\"Train models through GridSearchCV\"\"\"\n",
    "        params,models = self.load_models()\n",
    "        \n",
    "        # get X_train_scaled,X_test_scaled,y_train,y_test\n",
    "        \n",
    "        X_train_scaled,X_test_scaled,y_train,y_test = self.split()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        for model_name,(model,params) in models.items():\n",
    "            \n",
    "            \n",
    "            # grid-searcg\n",
    "            grid_search = GridSearchCV(model,params,cv=4,scoring=\"neg_mean_squared_error\",n_jobs=-1)\n",
    "            # fit grid search\n",
    "            grid_search.fit(X_train_scaled,y_train)\n",
    "            \n",
    "            y_pred = grid_search.predict(X_test_scaled)\n",
    "            \n",
    "            r2 = r2_score(y_test,y_pred)\n",
    "            print(f\"R2 Score->Model Name: {model_name} {r2*100:.2f}\")\n",
    "            \n",
    "            mape = mean_absolute_percentage_error(y_test,y_pred)\n",
    "            print(f\"Mean-Absolute Percentage Error: {model_name}--{mape:.4}\")\n",
    "            # best params\n",
    "            \n",
    "            best_params = grid_search.best_params_\n",
    "            \n",
    "            # best score\n",
    "            \n",
    "            best_score = grid_search.best_score_\n",
    "            \n",
    "            print(f\"Best Score for model: {model_name}<===>{best_score}\")\n",
    "            \n",
    "            print(f\"Best Params for model: {model_name}<====>{best_params}\")\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    config = load_config()\n",
    "    mt = ModelTrainer(config)\n",
    "    mt.train()     \n",
    "            \n",
    "        \n",
    "            \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
